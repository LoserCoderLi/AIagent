{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "import faiss\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.docstore.document import Document\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_by_lines(pdf_path):\n",
    "    \"\"\"使用 PyPDF2 从 PDF 文件中提取文本，并按行分割。\"\"\"\n",
    "    reader = PyPDF2.PdfReader(pdf_path)\n",
    "    lines = []\n",
    "    for page in reader.pages:\n",
    "        text = page.extract_text()\n",
    "        if text:\n",
    "            lines.extend(text.splitlines())  # 按行分割\n",
    "    return lines\n",
    "\n",
    "\n",
    "def process_pdf_with_langchain(pdf_path, hf_model):\n",
    "    \"\"\"使用LangChain处理PDF文件，按行分割文本并向量化。\"\"\"\n",
    "    lines = extract_text_by_lines(pdf_path)\n",
    "    documents = [Document(page_content=line) for line in lines if line.strip()]  # 过滤掉空行\n",
    "    return documents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_vectors_with_langchain(documents, hf_model, faiss_db_path):\n",
    "    \"\"\"将向量化的内容存储到FAISS中，并保存FAISS索引。\"\"\"\n",
    "    # 使用模型生成向量\n",
    "    embeddings = hf_model.embed_documents([doc.page_content for doc in documents])\n",
    "    \n",
    "    # 创建FAISS VectorStore\n",
    "    vectorstore = FAISS.from_documents(documents, hf_model)\n",
    "    \n",
    "    # 将FAISS索引保存到文件\n",
    "    vectorstore.save_local(faiss_db_path)\n",
    "\n",
    "    return vectorstore\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_and_store_pdf(pdf_path, hf_model, faiss_db_path):\n",
    "    \"\"\"处理PDF文件，向量化并存储到FAISS中。\"\"\"\n",
    "    # Step 1: 使用 LangChain 处理PDF并生成文档列表\n",
    "    documents = process_pdf_with_langchain(pdf_path, hf_model)\n",
    "    \n",
    "    # Step 2: 使用 LangChain 存储向量到 FAISS\n",
    "    vectorstore = store_vectors_with_langchain(documents, hf_model, faiss_db_path)\n",
    "    \n",
    "    return vectorstore\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 示例用法\n",
    "local_em_model_path = \"E:\\\\AAAAWork\\\\python\\\\models\\\\EMB\\\\bce-embedding-base_v1\"  # 替换为你的本地模型路径\n",
    "hf = HuggingFaceEmbeddings(\n",
    "    model_name=local_em_model_path,\n",
    "    model_kwargs={\"device\": \"cpu\"},  # 如果使用GPU，将 \"cpu\" 替换为 \"cuda\"\n",
    "    encode_kwargs={\"normalize_embeddings\": True},\n",
    ")\n",
    "\n",
    "pdf_path = R\"E:\\AAAAWork\\python\\LLM_RAG\\C2012\\demo\\contents.pdf\"  # 替换为你的PDF文件路径\n",
    "faiss_db_path = \"contents.index\"  # 指定保存FAISS索引的路径\n",
    "\n",
    "vectorstore = process_and_store_pdf(pdf_path, hf, faiss_db_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入必须的包\n",
    "from langchain.document_loaders import UnstructuredExcelLoader, Docx2txtLoader, PyPDFLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "# from langchain_community.embeddings import HuggingFaceBgeEmbeddings\n",
    "from langchain_community.embeddings import DashScopeEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "# 设置LLM\n",
    "from langchain_community.chat_models import ChatTongyi\n",
    "# 引入上下文压缩\n",
    "from langchain.retrievers import ContextualCompressionRetriever # 上下文压缩检索\n",
    "from langchain.retrievers.document_compressors import LLMChainExtractor\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = os.getenv(\"KEY_TONGYI\")\n",
    "serp_api_key = os.getenv(\"KEY_SEARCH\") #搜索平台Serp的API KEY\n",
    "os.environ[\"SERPAPI_API_KEY\"] = serp_api_key\n",
    "\n",
    "# LLM\n",
    "llm = ChatTongyi(\n",
    "    dashscope_api_key=api_key,\n",
    "    temperature=0 # 0-1，越小越倾向与输入一致\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChatDoc:\n",
    "    def __init__(self, faiss_db_path):\n",
    "        self.faiss_db_path = faiss_db_path\n",
    "        self.template = [\n",
    "            (\"system\", \"你是一个处理文档的秘书,你会根据下面提供的上下文内容来继续回答问题,你从不说自己是一个大模型或者AI助手.\\n上下文内容\\n{context}\\n\"),\n",
    "            (\"human\", \"你好!\\n\"),\n",
    "            (\"ai\", \"你好!\"),\n",
    "            (\"human\", \"{question}\\n\"),\n",
    "        ]\n",
    "        self.prompt = ChatPromptTemplate.from_messages(self.template)\n",
    "\n",
    "    # 加载向量数据库\n",
    "    def load_vector_db(self):\n",
    "        # 加载已经保存的 FAISS 索引\n",
    "        hf = HuggingFaceEmbeddings(\n",
    "            model_name=\"E:\\\\AAAAWork\\\\python\\\\models\\\\EMB\\\\bce-embedding-base_v1\",  # 替换为实际的模型路径\n",
    "            model_kwargs={\"device\": \"cpu\"},\n",
    "            encode_kwargs={\"normalize_embeddings\": True},\n",
    "        )\n",
    "        db = FAISS.load_local(self.faiss_db_path, hf, allow_dangerous_deserialization=True)\n",
    "        return db\n",
    "\n",
    "    # 提问并找到相关文本块\n",
    "    def askAndFindFiles(self, question):\n",
    "        db = self.load_vector_db()  # 加载已有的向量数据库\n",
    "        # 采用上下文压缩的方式\n",
    "        retriever = db.as_retriever()\n",
    "        compressor = LLMChainExtractor.from_llm(llm=llm)\n",
    "        compressor_retriever = ContextualCompressionRetriever(\n",
    "            base_compressor=compressor, base_retriever=retriever\n",
    "        )\n",
    "        return compressor_retriever.get_relevant_documents(query=question)\n",
    "\n",
    "    # 用自然语言和文档聊天\n",
    "    def chatWithDoc(self, question):\n",
    "        _context = \"\"\n",
    "        context = self.askAndFindFiles(question)\n",
    "        for i in context:\n",
    "            _context += i.page_content\n",
    "        message = self.prompt.format_messages(context=_context, question=question)\n",
    "        return llm.invoke(message)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error in __cdecl faiss::FileIOReader::FileIOReader(const char *) at D:\\a\\faiss-wheels\\faiss-wheels\\faiss\\faiss\\impl\\io.cpp:68: Error: 'f' failed: could not open content.index\\index.faiss for reading: No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_24236\\3077790331.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# 创建 ChatDoc 实例，并指定 FAISS 数据库的路径\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mchat_doc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mChatDoc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfaiss_db_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"content.index\"\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# 替换为实际的路径\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# 进行问题查询\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mchat_doc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchatWithDoc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"第一条内容是什么\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_24236\\3010985827.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, question)\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mchatWithDoc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mquestion\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[0m_context\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m         \u001b[0mcontext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maskAndFindFiles\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquestion\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m             \u001b[0m_context\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpage_content\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m         \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprompt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat_messages\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_context\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mquestion\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mquestion\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_24236\\3010985827.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, question)\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0maskAndFindFiles\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mquestion\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m         \u001b[0mdb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_vector_db\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# 加载已有的向量数据库\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m         \u001b[1;31m# 采用上下文压缩的方式\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[0mretriever\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_retriever\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[0mcompressor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLLMChainExtractor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_llm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mllm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mllm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_24236\\3010985827.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     16\u001b[0m             \u001b[0mmodel_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"E:\\\\AAAAWork\\\\python\\\\models\\\\EMB\\\\bce-embedding-base_v1\"\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# 替换为实际的模型路径\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m             \u001b[0mmodel_kwargs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m\"device\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m\"cpu\"\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m             \u001b[0mencode_kwargs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m\"normalize_embeddings\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         )\n\u001b[1;32m---> 20\u001b[1;33m         \u001b[0mdb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFAISS\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_local\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfaiss_db_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_dangerous_deserialization\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mdb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\AAAAWork\\python\\LLM_RAG\\demo\\lib\\site-packages\\langchain_community\\vectorstores\\faiss.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(cls, folder_path, embeddings, index_name, allow_dangerous_deserialization, **kwargs)\u001b[0m\n\u001b[0;32m   1197\u001b[0m             )\n\u001b[0;32m   1198\u001b[0m         \u001b[0mpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfolder_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1199\u001b[0m         \u001b[1;31m# load index separately since it is not picklable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1200\u001b[0m         \u001b[0mfaiss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdependable_faiss_import\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1201\u001b[1;33m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfaiss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;34mf\"{index_name}.faiss\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1202\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1203\u001b[0m         \u001b[1;31m# load docstore and index_to_docstore_id\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1204\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;34mf\"{index_name}.pkl\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\AAAAWork\\python\\LLM_RAG\\demo\\lib\\site-packages\\faiss\\swigfaiss_avx2.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m  10408\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mread_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m> 10409\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_swigfaiss_avx2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m: Error in __cdecl faiss::FileIOReader::FileIOReader(const char *) at D:\\a\\faiss-wheels\\faiss-wheels\\faiss\\faiss\\impl\\io.cpp:68: Error: 'f' failed: could not open content.index\\index.faiss for reading: No such file or directory"
     ]
    }
   ],
   "source": [
    "# 创建 ChatDoc 实例，并指定 FAISS 数据库的路径\n",
    "chat_doc = ChatDoc(faiss_db_path=\"contents.index\")  # 替换为实际的路径\n",
    "\n",
    "# 进行问题查询\n",
    "response = chat_doc.chatWithDoc(\"第一条内容是什么\")\n",
    "print(response)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "demo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
