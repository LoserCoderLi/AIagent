{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stuff Documents Chain 简单拼接"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 源码解析"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 类声明和装饰器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@deprecated(\n",
    "    since=\"0.2.13\",\n",
    "    removal=\"1.0\",\n",
    "    message=(\n",
    "        \"This class is deprecated. Use the `create_stuff_documents_chain` constructor \"\n",
    "        \"instead. See migration guide here: \"\n",
    "        \"https://python.langchain.com/v0.2/docs/versions/migrating_chains/stuff_docs_chain/\"  # noqa: E501\n",
    "    ),\n",
    ")\n",
    "class StuffDocumentsChain(BaseCombineDocumentsChain):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `@deprecated` 装饰器标识该类将被弃用，并指引用户使用新的构造函数 `create_stuff_documents_chain`。\n",
    "- 该类继承自 `BaseCombineDocumentsChain`，意味着它实现了基于文档组合的功能。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 类属性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_chain: LLMChain\n",
    "document_prompt: BasePromptTemplate = Field(default_factory=lambda: DEFAULT_DOCUMENT_PROMPT)\n",
    "document_variable_name: str\n",
    "document_separator: str = \"\\n\\n\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `llm_chain`：用于处理组合后的文档和其他输入的 LLM 链。\n",
    "- `document_prompt`：用来格式化每个文档的提示模板。默认使用 DEFAULT_DOCUMENT_PROMPT。\n",
    "- `document_variable_name`：将格式化后的文档字符串放置在 `llm_chain` 中的变量名。\n",
    "- `document_separator`：在格式化后的文档字符串之间使用的分隔符，默认为换行符 \\n\\n。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 配置类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    arbitrary_types_allowed = True\n",
    "    extra = \"forbid\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `arbitrary_types_allowed`：允许在 `Pydantic` 模型中使用任意类型。\n",
    "- `extra = \"forbid\"`：禁止在模型中定义未声明的额外字段。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `get_default_document_variable_name` 方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@root_validator(pre=True)\n",
    "def get_default_document_variable_name(cls, values: Dict) -> Dict:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `get_default_document_variable_name` 是一个根验证器，用于在实例化前设置或验证 `document_variable_name`。\n",
    "- 该方法会检查 `llm_chain` 的输入变量，决定是否需要自动设置 `document_variable_name`。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `input_keys` 属性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@property\n",
    "def input_keys(self) -> List[str]:\n",
    "    extra_keys = [k for k in self.llm_chain.input_keys if k != self.document_variable_name]\n",
    "    return super().input_keys + extra_keys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `input_keys` 返回这个链所需的所有输入键。除了 `super().input_keys` 返回的输入键，还包括 `llm_chain` 中不包含在 `document_variable_name` 中的额外键。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `_get_inputs` 方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_inputs(self, docs: List[Document], **kwargs: Any) -> dict:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `_get_inputs` 方法负责将文档列表格式化并拼接成一个字符串，然后将其与其他 `kwargs` 一起组织成 `llm_chain` 需要的输入字典。\n",
    "- 该方法先将每个文档通过 `document_prompt` 进行格式化，然后使用 `document_separator` 拼接这些字符串。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `prompt_length` 方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt_length(self, docs: List[Document], **kwargs: Any) -> Optional[int]:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `prompt_length` 方法计算格式化后的文档列表长度，以便调用者能提前判断这些文档是否会超出 `LLM` 的输入限制。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### combine_docs 和 acombine_docs 方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_docs(self, docs: List[Document], callbacks: Callbacks = None, **kwargs: Any) -> Tuple[str, dict]:\n",
    "\n",
    "async def acombine_docs(\n",
    "        self, docs: List[Document], callbacks: Callbacks = None, **kwargs: Any\n",
    "    ) -> Tuple[str, dict]:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `combine_docs` 是将所有文档合并为一个字符串，并传递给 `LLM` 的主要方法。\n",
    "- 它调用 `llm_chain.predict` 方法，传递格式化后的文档字符串和其他输入参数。\n",
    "- `acombine_docs` 是其异步版本。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `_chain_type` 属性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@property\n",
    "def _chain_type(self) -> str:\n",
    "    return \"stuff_documents_chain\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `_chain_type` 返回链的类型标识符，这里它标识为 `\"stuff_documents_chain\"`。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用场景\n",
    "你可以将这个类用于以下场景：\n",
    "\n",
    "- 当你有一组相关的文档，需要将它们组合成一个`大的`上下文，并通过 LLM 生成总结、回答问题等。\n",
    "- 它可以在需要将`大量数据传`递给模型的情况下使用。\n",
    "然而，由于这个类被标记为过时，推荐使用新的构造器 `create_stuff_documents_chain` 来实现类似功能"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_models import ChatTongyi\n",
    "from langchain.chains.combine_documents.stuff import StuffDocumentsChain\n",
    "from langchain.chains.llm import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.docstore.document import Document\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e:\\AAAAWork\\python\\LLM_RAG\\chain\\四种文档预制链\\template\\tika-server-standard-2.6.0.jar\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 从环境变量中获取API密钥，用于初始化 ChatTongyi 模型\n",
    "api_key = os.getenv(\"KEY_TONGYI\")\n",
    "if not api_key:\n",
    "    raise ValueError(\"API Key is not set. Please ensure that the 'KEY_TONGYI' environment variable is set.\")\n",
    "\n",
    "\n",
    "# 打印并设置Tika服务器的路径，使用本地运行的 Tika Server 解析文件\n",
    "print(os.path.abspath('./template/tika-server-standard-2.6.0.jar'))\n",
    "os.environ['TIKA_SERVER_JAR'] = 'http://localhost:9998/'\n",
    "\n",
    "\n",
    "# 初始化 ChatTongyi 模型，设置文本生成的温度参数，温度越低生成的文本越接近输入\n",
    "llm = ChatTongyi(\n",
    "    dashscope_api_key=api_key,\n",
    "    temperature=0,  # 设置生成文本的倾向，值越小生成的文本越接近输入\n",
    "    streaming=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义模板\n",
    "document_prompt = PromptTemplate(\n",
    "  input_variables=['page_content'],\n",
    "  template=\"{page_content}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义文档组合后将其传递给 LLM 的变量名称\n",
    "document_variable_name = \"context\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义要使用的 LLM 提示模板，包含组合后的文档\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"Summarize this content: {context}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\AAAAWork\\python\\LLM_RAG\\demo\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:141: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use RunnableSequence, e.g., `prompt | llm` instead.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "# 将 LLM 和提示模板结合成一个链\n",
    "llm_chain = LLMChain(llm=llm, prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\AAAAWork\\python\\LLM_RAG\\demo\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:141: LangChainDeprecationWarning: This class is deprecated. Use the `create_stuff_documents_chain` constructor instead. See migration guide here: https://python.langchain.com/v0.2/docs/versions/migrating_chains/stuff_docs_chain/\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "# 初始化 StuffDocumentsChain\n",
    "chain = StuffDocumentsChain(\n",
    "    llm_chain=llm_chain,\n",
    "    document_prompt=document_prompt,\n",
    "    document_variable_name=document_variable_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 准备一组文档\n",
    "docs = [\n",
    "    Document(page_content=\"LangChain 是一个强大的库，帮助你轻松处理文档。\"),\n",
    "    Document(page_content=\"OpenAI 的 GPT-3 模型提供了强大的文本生成能力。\"),\n",
    "    Document(page_content=\"通过组合这些工具，你可以实现强大的 NLP 应用。\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangChain 是一个强大的库，专为简化文档处理而设计，使得构建高效、可扩展的文本应用变得更加容易。与此同时，OpenAI 的 GPT-3 模型以其卓越的文本生成能力著称，能够根据输入生成高度相关且上下文连贯的文本内容。将 LangChain 与 GPT-3 结合使用，可以显著提升自然语言处理（NLP）应用的性能和复杂度。这种集成不仅能够增强文本理解、生成和处理的能力，还能够应用于各种场景，如智能客服、文本摘要、对话系统等，从而创造出更为智能、交互性更强的应用程序。通过充分利用这两个工具的优势，开发者能够快速构建出具有深度学习能力的 NLP 应用，满足从基础文本分析到高度个性化响应的广泛需求。\n"
     ]
    }
   ],
   "source": [
    "# 使用 StuffDocumentsChain 处理文档并生成总结\n",
    "output, _ = chain.combine_docs(docs)\n",
    "\n",
    "# 打印生成的总结\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = chain._get_inputs(docs=docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'context': 'LangChain 是一个强大的库，帮助你轻松处理文档。\\n\\nOpenAI 的 GPT-3 模型提供了强大的文本生成能力。\\n\\n通过组合这些工具，你可以实现强大的 NLP 应用。'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data # 简单拼接"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "demo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
