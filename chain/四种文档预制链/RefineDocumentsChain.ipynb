{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Refine Documents Chain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 介绍"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "`RefineDocumentsChain` 的结构和工作原理不仅限于生成总结。实际上，它可以应用于任何需要逐步处理多个输入的任务，无论是生成总结、回答问题、进行翻译，还是其他需要递归处理并逐步扩展上下文的应用场景。\n",
    "\n",
    "### **泛化的工作原理**\n",
    "\n",
    "1. **初步处理**：\n",
    "   - `initial_llm_chain` 使用 `initial_prompt_template` 对第一个文档（或第一个输入）进行初步处理。这个过程可以是生成一个总结、翻译一段文字、提取关键信息等。\n",
    "\n",
    "2. **细化处理**：\n",
    "   - 随后的文档（或输入）与之前生成的结果结合，通过 `refine_llm_chain` 和 `refine_prompt_template` 进行进一步的处理。这个处理会在之前结果的基础上，结合新的内容，生成一个更为复杂或完整的输出。\n",
    "\n",
    "### **应用场景示例**\n",
    "\n",
    "- **总结生成**：\n",
    "  - 初步总结一个段落，然后逐步添加更多段落的总结内容，形成一个完整的文档总结。\n",
    "\n",
    "- **问题回答**：\n",
    "  - 初步回答一个简单的问题，然后通过后续的输入不断细化答案，直到生成一个更详细、全面的回答。\n",
    "\n",
    "- **翻译文本**：\n",
    "  - 初步翻译一段文字，然后逐步翻译更多的内容，将之前的翻译结果和新的内容结合，生成一个连贯的完整翻译。\n",
    "\n",
    "- **信息提取**：\n",
    "  - 初步提取一段文字中的关键信息，然后逐步结合更多内容，提取出更为复杂的关系或信息。\n",
    "\n",
    "### **递归处理的优势**\n",
    "\n",
    "- **保持上下文**：每一步都能保持对之前结果的记忆，使得最终输出能够综合多个输入的内容。\n",
    "- **递归扩展**：通过逐步处理，可以将复杂任务拆分为多个简单步骤，逐步扩展并完善最终结果。\n",
    "- **灵活性**：可以通过调整模板和链条的定义，应用于广泛的任务，不局限于总结生成。\n",
    "\n",
    "因此，`RefineDocumentsChain` 是一种非常通用的链式处理机制，能够递归地处理多个输入，并结合之前的结果生成新的输出。这种结构不仅适用于总结生成，而且可以扩展到许多需要递归处理并逐步构建输出的场景中。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 源码分析"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 类的定义和文档字符串"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RefineDocumentsChain(BaseCombineDocumentsChain):\n",
    "    \"\"\"Combine documents by doing a first pass and then refining on more documents.\n",
    "\n",
    "    This algorithm first calls `initial_llm_chain` on the first document, passing\n",
    "    that first document in with the variable name `document_variable_name`, and\n",
    "    produces a new variable with the variable name `initial_response_name`.\n",
    "\n",
    "    Then, it loops over every remaining document. This is called the \"refine\" step.\n",
    "    It calls `refine_llm_chain`,\n",
    "    passing in that document with the variable name `document_variable_name`\n",
    "    as well as the previous response with the variable name `initial_response_name`.\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`RefineDocumentsChain` 是一个链条类，它用于逐步处理多个文档。首先，它会对第一个文档进行初步处理，然后对每个后续文档进行细化处理。在初步处理步骤中，链条会将第一个文档传递给 `initial_llm_chain`，生成一个初始响应。然后，在细化步骤中，它会依次将每个剩余文档与之前生成的响应一起传递给 `refine_llm_chain` 进行进一步处理。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 成员变量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 初步处理链条`initial_llm_chain`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    initial_llm_chain: LLMChain\n",
    "    \"\"\"LLM chain to use on initial document.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`initial_llm_chain` 是一个 LLMChain 对象，用于初步处理第一个文档。这一链条负责生成对第一个文档的**初步总结**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 细化处理链条`refine_llm_chain`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    refine_llm_chain: LLMChain\n",
    "    \"\"\"LLM chain to use when refining.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`refine_llm_chain` 是一个 LLMChain 对象，用于细化处理后续的文档。它**接收前一步生成的总结**，并结合当前文档**生成更详细的总结**。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 文档变量名 `document_variable_name`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    document_variable_name: str\n",
    "    \"\"\"The variable name in the initial_llm_chain to put the documents in.\n",
    "    If only one variable in the initial_llm_chain, this need not be provided.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`document_variable_name` 定义了文档内容在 LLM 链中使用的变量名。它是链条在处理文档时用来标识文档内容的关键字。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 初步响应变量名 `initial_response_name`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    initial_response_name: str\n",
    "    \"\"\"The variable name to format the initial response in when refining.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`initial_response_name` 是在细化过程中用于传递初步总结结果的变量名。这个变量名用于标识初步处理的结果，以便在细化处理步骤中使用"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 文档提示模板 `document_prompt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    document_prompt: BasePromptTemplate = Field(\n",
    "        default_factory=_get_default_document_prompt\n",
    "    )\n",
    "    \"\"\"Prompt to use to format each document, gets passed to `format_document`.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`document_prompt` 是一个提示模板，用于格式化文档的内容。在处理文档时，链条会使用这个模板来生成输入给 LLM 的格式化文本。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 是否返回中间步骤 `return_intermediate_steps`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    return_intermediate_steps: bool = False\n",
    "    \"\"\"Return the results of the refine steps in the output.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`return_intermediate_steps` 是一个布尔值，用于决定是否在最终输出中包含每个细化步骤的中间结果。如果设置为 `True`，链条会返回每个文档处理后的中间结果。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 输出键设置函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    @property\n",
    "    def output_keys(self) -> List[str]:\n",
    "        \"\"\"Expect input key.\n",
    "\n",
    "        :meta private:\n",
    "        \"\"\"\n",
    "        _output_keys = super().output_keys\n",
    "        if self.return_intermediate_steps:\n",
    "            _output_keys = _output_keys + [\"intermediate_steps\"]\n",
    "        return _output_keys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`output_keys` 方法返回链条的输出键名列表。如果 `return_intermediate_steps` 为 `True`，链条会在输出中添加 `intermediate_steps`，这是一个包含中间处理结果的列表。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 初始化变量校验函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    @root_validator(pre=True)\n",
    "    def get_default_document_variable_name(cls, values: Dict) -> Dict:\n",
    "        \"\"\"Get default document variable name, if not provided.\"\"\"\n",
    "        if \"initial_llm_chain\" not in values:\n",
    "            raise ValueError(\"initial_llm_chain must be provided\")\n",
    "\n",
    "        llm_chain_variables = values[\"initial_llm_chain\"].prompt.input_variables\n",
    "        if \"document_variable_name\" not in values:\n",
    "            if len(llm_chain_variables) == 1:\n",
    "                values[\"document_variable_name\"] = llm_chain_variables[0]\n",
    "            else:\n",
    "                raise ValueError(\n",
    "                    \"document_variable_name must be provided if there are \"\n",
    "                    \"multiple llm_chain input_variables\"\n",
    "                )\n",
    "        else:\n",
    "            if values[\"document_variable_name\"] not in llm_chain_variables:\n",
    "                raise ValueError(\n",
    "                    f\"document_variable_name {values['document_variable_name']} was \"\n",
    "                    f\"not found in llm_chain input_variables: {llm_chain_variables}\"\n",
    "                )\n",
    "        return values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这个校验器在类实例化时确保 `document_variable_name` 被正确设置。如果没有提供 `document_variable_name`，但 `initial_llm_chain` 只有一个输入变量，那么这个变量名会自动设为 `initial_llm_chain` 的输入变量名。如果 `document_variable_name` 不存在于 `initial_llm_chain` 的输入变量中，则会抛出错误。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 文档组合逻辑函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### 同步文档组合`combine_docs`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def combine_docs(\n",
    "        self, docs: List[Document], callbacks: Callbacks = None, **kwargs: Any\n",
    "    ) -> Tuple[str, dict]:\n",
    "        \"\"\"Combine by mapping first chain over all, then stuffing into final chain.\n",
    "\n",
    "        Args:\n",
    "            docs: List of documents to combine\n",
    "            callbacks: Callbacks to be passed through\n",
    "            **kwargs: additional parameters to be passed to LLM calls (like other\n",
    "                input variables besides the documents)\n",
    "\n",
    "        Returns:\n",
    "            The first element returned is the single string output. The second\n",
    "            element returned is a dictionary of other keys to return.\n",
    "        \"\"\"\n",
    "        inputs = self._construct_initial_inputs(docs, **kwargs)\n",
    "        res = self.initial_llm_chain.predict(callbacks=callbacks, **inputs)\n",
    "        refine_steps = [res]\n",
    "        for doc in docs[1:]:\n",
    "            base_inputs = self._construct_refine_inputs(doc, res)\n",
    "            inputs = {**base_inputs, **kwargs}\n",
    "            res = self.refine_llm_chain.predict(callbacks=callbacks, **inputs)\n",
    "            refine_steps.append(res)\n",
    "        return self._construct_result(refine_steps, res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`combine_docs` 方法通过初步处理第一个文档，然后逐步细化剩余文档来组合多个文档。它首先构建初始输入，并使用 `initial_llm_chain` 生成初步结果。接着，对剩余的每个文档，它构建细化步骤的输入，并使用 `refine_llm_chain` 生成最终结果。如果 `return_intermediate_steps` 为 `True`，它会返回中间步骤的结果。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 异步文档组合`acombine_docs`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    async def acombine_docs(\n",
    "        self, docs: List[Document], callbacks: Callbacks = None, **kwargs: Any\n",
    "    ) -> Tuple[str, dict]:\n",
    "        \"\"\"Async combine by mapping a first chain over all, then stuffing\n",
    "         into a final chain.\n",
    "\n",
    "        Args:\n",
    "            docs: List of documents to combine\n",
    "            callbacks: Callbacks to be passed through\n",
    "            **kwargs: additional parameters to be passed to LLM calls (like other\n",
    "                input variables besides the documents)\n",
    "\n",
    "        Returns:\n",
    "            The first element returned is the single string output. The second\n",
    "            element returned is a dictionary of other keys to return.\n",
    "        \"\"\"\n",
    "        inputs = self._construct_initial_inputs(docs, **kwargs)\n",
    "        res = await self.initial_llm_chain.apredict(callbacks=callbacks, **inputs)\n",
    "        refine_steps = [res]\n",
    "        for doc in docs[1:]:\n",
    "            base_inputs = self._construct_refine_inputs(doc, res)\n",
    "            inputs = {**base_inputs, **kwargs}\n",
    "            res = await self.refine_llm_chain.apredict(callbacks=callbacks, **inputs)\n",
    "            refine_steps.append(res)\n",
    "        return self._construct_result(refine_steps, res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`acombine_docs` 是 `combine_docs` 方法的异步版本，用于在异步环境中执行相同的逻辑。它与同步方法的工作流程相同，只是使用 `await` 关键字处理异步操作。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 结果构造函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def _construct_result(self, refine_steps: List[str], res: str) -> Tuple[str, dict]:\n",
    "        if self.return_intermediate_steps:\n",
    "            extra_return_dict = {\"intermediate_steps\": refine_steps}\n",
    "        else:\n",
    "            extra_return_dict = {}\n",
    "        return res, extra_return_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`_construct_result` 方法根据是否需要返回中间步骤来构建最终结果。如果 `return_intermediate_steps` 为 `True`，它会在返回的字典中包含一个 `intermediate_steps` 键，存放所有细化步骤的结果。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 构建细化步骤的输入函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def _construct_refine_inputs(self, doc: Document, res: str) -> Dict[str, Any]:\n",
    "        return {\n",
    "            self.document_variable_name: format_document(doc, self.document_prompt),\n",
    "            self.initial_response_name: res,\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`_construct_refine_inputs` 方法构建细化步骤的输入。它将当前文档格式化后，与**之前生成的总结结果一起作为输入**，传递给 `refine_llm_chain` 处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 构建初始化步骤的输入函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def _construct_initial_inputs(\n",
    "        self, docs: List[Document], **kwargs: Any\n",
    "    ) -> Dict[str, Any]:\n",
    "        base_info = {\"page_content\": docs[0].page_content}\n",
    "        base_info.update(docs[0].metadata)\n",
    "        document_info = {k: base_info[k] for k in self.document_prompt.input_variables}\n",
    "        base_inputs: dict = {\n",
    "            self.document_variable_name: self.document_prompt.format(**document_info)\n",
    "        }\n",
    "        inputs = {**base_inputs, **kwargs}\n",
    "        return inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`_construct_initial_inputs` 方法构建初步处理步骤的输入。它将第一个文档的内容和元数据格式化，并构造初步处理链条所需的输入字典。这个字典会包含文档内容及任何其他需要传递的参数。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 链条类型函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    @property\n",
    "    def _chain_type(self) -> str:\n",
    "        return \"refine_documents_chain\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`_chain_type` 返回链条的类型，这个类型在框架内部可能用于识别链条的类别或选择不同的处理策略。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.combine_documents.refine import RefineDocumentsChain\n",
    "from langchain.chains.llm import LLMChain\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_community.chat_models import ChatTongyi\n",
    "from langchain.docstore.document import Document\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 总结\n",
    "# 初步处理文档的提示模板\n",
    "initial_prompt_template = PromptTemplate(\n",
    "  input_variables=[\"context\"],\n",
    "  template=\"总结这个内容:{context}\"\n",
    ")\n",
    "\n",
    "# 细化处理文档的提示模板\n",
    "refine_prompt_template = PromptTemplate(\n",
    "  input_variables=[\"context\", \"prev_response\"],\n",
    "  template=(\n",
    "    \"这是前一个内容的总结:{prev_response}\"\n",
    "    \"现在，在这个总结的基础上添加下面内容的总结:{context}\"\n",
    "  )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 从环境变量中获取API密钥，用于初始化 ChatTongyi 模型\n",
    "api_key = os.getenv(\"KEY_TONGYI\")\n",
    "if not api_key:\n",
    "    raise ValueError(\"API Key is not set. Please ensure that the 'KEY_TONGYI' environment variable is set.\")\n",
    "\n",
    "\n",
    "# 初始化 ChatTongyi 模型，设置文本生成的温度参数，温度越低生成的文本越接近输入\n",
    "llm = ChatTongyi(\n",
    "    dashscope_api_key=api_key,\n",
    "    temperature=0,  # 设置生成文本的倾向，值越小生成的文本越接近输入\n",
    "    streaming=True\n",
    ")\n",
    "# 初步处理链和细化处理链\n",
    "initial_chains = LLMChain(llm = llm, prompt=initial_prompt_template)\n",
    "refine_chains = LLMChain(llm=llm, prompt=refine_prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建 RefineDocumentsChain\n",
    "refine_chain = RefineDocumentsChain(\n",
    "    initial_llm_chain=initial_chains,\n",
    "    refine_llm_chain=refine_chains,\n",
    "    document_variable_name=\"context\",\n",
    "    initial_response_name=\"prev_response\",\n",
    "    return_intermediate_steps=True  # 如果需要返回中间步骤的结果，可以设置为 True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 准备一组文档\n",
    "docs = [\n",
    "    Document(page_content=\"LangChain 是一个强大的库，帮助你轻松处理文档。\"),\n",
    "    Document(page_content=\"OpenAI 的 GPT-3 模型提供了强大的文本生成能力。\"),\n",
    "    Document(page_content=\"通过组合这些工具，你可以实现强大的 NLP 应用。\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Summary:\n",
      "通过整合GPT-3模型以及其他自然语言处理（NLP）工具和技术，开发者和专业人士能够构建出功能强大、高效且针对性强的NLP应用。以下是基于上述总结基础上的扩展内容：\n",
      "\n",
      "1. **集成多种NLP技术**：除了GPT-3模型，还可以结合其他NLP技术如命名实体识别、情感分析、语义解析、机器翻译等，以实现更全面的文本理解和处理能力。例如，通过集成情感分析工具，可以增强GPT-3模型在生成评论、反馈或社交媒体分析时的情感洞察力。\n",
      "\n",
      "2. **个性化定制**：利用GPT-3模型的可微调特性，可以针对特定行业、领域或应用场景进行定制化训练，使模型能够更加精准地满足特定需求。例如，在金融领域，可以针对特定的交易策略、市场分析报告或风险评估报告进行微调，以提供更加专业和个性化的服务。\n",
      "\n",
      "3. **自动化流程优化**：将GPT-3模型与其他自动化工具结合，可以优化工作流程，提高效率。比如，结合文档生成工具和GPT-3模型，可以自动完成合同起草、报告撰写等工作，减少人工操作的时间和成本。\n",
      "\n",
      "4. **多模态处理**：虽然GPT-3模型主要处理文本数据，但通过与图像识别、语音合成等技术的集成，可以实现文本、图像、语音等多种模态信息的综合处理，提升应用的交互性和实用性。例如，在智能客服系统中，不仅能够理解文字问题，还能通过语音识别理解口头询问，并通过语音合成提供回复。\n",
      "\n",
      "5. **跨语言支持**：借助于GPT-3模型的翻译能力以及与其他语言处理工具的集成，可以构建支持多语言的NLP应用，满足全球化市场的需求。这不仅限于翻译服务，还包括多语言文本分析、内容本地化等应用。\n",
      "\n",
      "6. **持续学习与迭代**：通过持续收集用户反馈和新数据，不断训练和更新模型，可以保持NLP应用的性能和相关性。这要求有良好的数据管理、监控和自动化流程，确保模型能够适应变化的环境和用户需求。\n",
      "\n",
      "总之，通过整合GPT-3模型与其他NLP工具和技术，可以构建出功能丰富、适应性强的NLP应用，解决从文本生成到多模态处理、从自动化流程优化到多语言支持的广泛问题。\n",
      "\n",
      "Intermediate Steps:\n",
      "Step 1: LangChain 是一个功能丰富的库，专门设计用于简化和优化文档的处理流程。它提供了一系列工具和功能，使得用户能够高效地进行文档的读取、解析、存储、检索以及后续的文本分析任务。以下是对 LangChain 主要特性的简要总结：\n",
      "\n",
      "1. **文档处理**：LangChain 支持多种格式的文档，包括 PDF、Word 文档、Markdown、HTML 等，允许用户轻松加载和处理这些格式的文件。\n",
      "\n",
      "2. **结构化提取**：通过使用自然语言处理技术，LangChain 能够从文档中自动提取关键信息，如标题、段落、列表、表格等，为后续的数据分析和利用奠定基础。\n",
      "\n",
      "3. **文本检索**：LangChain 提供了高效的文本检索功能，允许用户根据关键词、句子或特定模式快速查找文档中的相关信息，支持全文搜索和精确匹配。\n",
      "\n",
      "4. **集成与扩展性**：该库与其他数据处理和分析工具（如 NLP 库、数据库管理系统等）兼容，方便用户构建端到端的数据处理和分析系统。\n",
      "\n",
      "5. **自动化工作流**：LangChain 可以帮助自动化文档处理流程，从文档导入、解析到结果输出，减少人工干预，提高工作效率。\n",
      "\n",
      "6. **安全性与隐私保护**：在处理敏感文档时，LangChain 强调数据的安全性和隐私保护，确保用户数据得到妥善管理和保护。\n",
      "\n",
      "总之，LangChain 通过其强大的功能集，为文档处理提供了一站式的解决方案，无论是学术研究、企业报告分析还是日常办公需求，都能提供高效、便捷的支持。\n",
      "Step 2: OpenAI的GPT-3模型是当前最先进的大型预训练语言模型之一，它具有惊人的文本生成能力。GPT-3模型能够理解并模仿人类语言的复杂性和多样性，从而生成高质量的文本内容。以下是对GPT-3模型主要特性的简要总结：\n",
      "\n",
      "1. **高度通用性**：GPT-3模型可以应用于各种文本生成任务，包括但不限于文章撰写、对话模拟、故事创作、代码生成、摘要提取、翻译等。\n",
      "\n",
      "2. **自动生成能力**：借助于深度学习技术，GPT-3模型能够根据给定的输入自动生成连贯且有意义的文本，无需额外的训练数据或指导。\n",
      "\n",
      "3. **上下文理解**：模型能够理解并适应不同领域的专业术语和复杂的语境，生成符合特定情境的文本。\n",
      "\n",
      "4. **持续改进**：GPT-3模型可以通过微调（fine-tuning）来适应特定的任务需求，实现对特定领域知识的掌握和应用。\n",
      "\n",
      "5. **创意与创新**：除了生成标准的文本内容外，GPT-3模型还能激发新的想法和创意，帮助用户探索不同的观点和解决方案。\n",
      "\n",
      "6. **道德与责任**：随着模型的应用越来越广泛，OpenAI强调了对其使用的伦理考量，确保模型的使用符合社会道德规范。\n",
      "\n",
      "综上所述，GPT-3模型凭借其强大的文本生成能力，为各种需要高质量文本内容的应用场景提供了有力支持，从创意写作到专业文档生成，GPT-3都展现了其独特的优势。\n",
      "Step 3: 通过整合GPT-3模型以及其他自然语言处理（NLP）工具和技术，开发者和专业人士能够构建出功能强大、高效且针对性强的NLP应用。以下是基于上述总结基础上的扩展内容：\n",
      "\n",
      "1. **集成多种NLP技术**：除了GPT-3模型，还可以结合其他NLP技术如命名实体识别、情感分析、语义解析、机器翻译等，以实现更全面的文本理解和处理能力。例如，通过集成情感分析工具，可以增强GPT-3模型在生成评论、反馈或社交媒体分析时的情感洞察力。\n",
      "\n",
      "2. **个性化定制**：利用GPT-3模型的可微调特性，可以针对特定行业、领域或应用场景进行定制化训练，使模型能够更加精准地满足特定需求。例如，在金融领域，可以针对特定的交易策略、市场分析报告或风险评估报告进行微调，以提供更加专业和个性化的服务。\n",
      "\n",
      "3. **自动化流程优化**：将GPT-3模型与其他自动化工具结合，可以优化工作流程，提高效率。比如，结合文档生成工具和GPT-3模型，可以自动完成合同起草、报告撰写等工作，减少人工操作的时间和成本。\n",
      "\n",
      "4. **多模态处理**：虽然GPT-3模型主要处理文本数据，但通过与图像识别、语音合成等技术的集成，可以实现文本、图像、语音等多种模态信息的综合处理，提升应用的交互性和实用性。例如，在智能客服系统中，不仅能够理解文字问题，还能通过语音识别理解口头询问，并通过语音合成提供回复。\n",
      "\n",
      "5. **跨语言支持**：借助于GPT-3模型的翻译能力以及与其他语言处理工具的集成，可以构建支持多语言的NLP应用，满足全球化市场的需求。这不仅限于翻译服务，还包括多语言文本分析、内容本地化等应用。\n",
      "\n",
      "6. **持续学习与迭代**：通过持续收集用户反馈和新数据，不断训练和更新模型，可以保持NLP应用的性能和相关性。这要求有良好的数据管理、监控和自动化流程，确保模型能够适应变化的环境和用户需求。\n",
      "\n",
      "总之，通过整合GPT-3模型与其他NLP工具和技术，可以构建出功能丰富、适应性强的NLP应用，解决从文本生成到多模态处理、从自动化流程优化到多语言支持的广泛问题。\n"
     ]
    }
   ],
   "source": [
    "# 使用 RefineDocumentsChain 处理文档\n",
    "final_summary, intermediate_results = refine_chain.combine_docs(docs)\n",
    "\n",
    "# 打印最终的总结\n",
    "print(\"Final Summary:\")\n",
    "print(final_summary)\n",
    "\n",
    "# 打印中间步骤的结果\n",
    "if \"intermediate_steps\" in intermediate_results:\n",
    "    print(\"\\nIntermediate Steps:\")\n",
    "    for step, result in enumerate(intermediate_results[\"intermediate_steps\"], 1):\n",
    "        print(f\"Step {step}: {result}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "demo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
